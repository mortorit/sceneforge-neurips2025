<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <meta name="title" content="SCENEFORGE">
  <meta name="description" content="
A novel compositional data pipeline for 3D-text contrastive learning, synthesizing multi-object 3D scenes with LLM-refined captions.

Consistent and significant performance gains across a wide range of tasks (zero-shot classification, segmentation, VQA) and multiple 3D encoder backbones.

A systematic analysis of key design choices, providing insights into optimal object counts, compositional ratios, and 3D composition strategies.">
  <meta name="keywords" content="contrastive leraning, multimodal, 3D, compositionality">
  <meta name="author" content="Cristian Sbrolli, Matteo Matteucci">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Artificial Intelligence and Robotics Laboratory, Politecnico di Milano">
  <meta property="og:title" content="SCENEFORGE: Enhancing 3D-text alignment with Structured Scene Compositions.">
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <meta property="og:url" content="">
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <meta name="twitter:title" content="PAPER_TITLE">
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <meta name="citation_title" content="PAPER_TITLE">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>SCENEFORGE: Enhancing 3D-text alignment with Structured Scene Compositions. - Cristian Sbrolli, Matteo Matteucci</title>
  
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>

  <style>
    .section-image {
      display: flex;
      justify-content: center;
      align-items: center;
    }
    .section-image img {
      max-width: 100%;
      height: auto;
      border-radius: 10px;
      box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    }
    .content h2 {
      font-weight: 600;
      margin-bottom: 1rem;
    }
  </style>
  </head>
<body>


  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">SCENEFORGE: Enhancing 3D-text alignment with Structured Scene Compositions.</h1>
          
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://sites.google.com/view/cristiansbrolli/home" target="https://sites.google.com/view/cristiansbrolli/home">Cristian Sbrolli</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://matteucci.faculty.polimi.it/home.html" target="https://matteucci.faculty.polimi.it/home.html">Matteo Matteucci</a><sup></sup>,</span>
                  </div>


                  <div class="is-size-5 publication-authors">
                  <span class="author-block">AIRLab<br>Politecnico di Milano</span>
                  </div>
                  <div class="is-size-5 publication-authors">
                    <span class="author-block glow-text">To appear in NeurIPS 2025</span>
                  </div>
                  <style>
                    .glow-text {
                      color: #2563eb;
                      text-shadow:
                        0 0 8px #2563eb,
                        0 0 16px #2563eb,
                        0 0 24px #2563eb,
                        0 0 32px #2563eb;
                      font-weight: 700;
                      animation: glow-pulse 1.5s infinite alternate;
                    }
                    @keyframes glow-pulse {
                      from {
                        text-shadow:
                          0 0 8px #2563eb,
                          0 0 16px #2563eb,
                          0 0 24px #2563eb,
                          0 0 32px #2563eb;
                      }
                      to {
                        text-shadow:
                          0 0 16px #2563eb,
                          0 0 32px #2563eb,
                          0 0 48px #2563eb,
                          0 0 64px #2563eb;
                      }
                    }
                  </style>

                  <div class="column has-text-centered">
                  <div class="publication-links">
                      <span class="link-block">
                    <a href="" target="https://arxiv.org/abs/2509.15693"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark" disabled>
                    <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                  </span>

                  <span class="link-block">
                  <a href="" target="_blank"
                  class="external-link button is-normal is-rounded is-dark" disabled>
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2509.15693v1" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The whole is greater than the sum of its partsâ€”even in 3D-text contrastive learning. We introduce SCENEFORGE, a novel framework that enhances contrastive alignment between 3D point clouds and text through structured multi-object scene compositions. SCENEFORGE leverages individual 3D shapes to construct multi-object scenes with explicit spatial relations, pairing them with coherent multi-object descriptions refined by a large language model. By augmenting contrastive training with these structured, compositional samples, SCENEFORGE effectively addresses the scarcity of large-scale 3D-text datasets, significantly enriching data complexity and diversity. Extensive experiments demonstrate that SCENEFORGE delivers substantial performance gains across multiple tasks, including zero-shot classification on ModelNet, ScanObjNN, Objaverse-LVIS, and ScanNet, as well as few-shot part segmentation on ShapeNetPart. SCENEFORGE'S compositional augmentations are model-agnostic, consistently improving performance across multiple encoder architectures. Moreover, SCENEFORGE improves 3D visual question answering on ScanQA, generalizes robustly to retrieval scenarios with increasing scene complexity, and showcases spatial reasoning capabilities by adapting spatial configurations to align precisely with textual instructions.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-vcentered">
            <div class="column">
                <div class="content">
                    <h2>The Challenge: Data Scarcity in 3D-Text Learning</h2>
                    <p>
                        Scaling contrastive learning to 3D is challenging due to the limited availability of large-scale 3D-text datasets, especially when compared to the vast resources in the 2D domain. This data scarcity makes it difficult for models to learn robust and generalizable representations of the complex 3D world. Our work introduces a new strategy to synthetically enrich data complexity and diversity, pushing the boundaries of what's possible in 3D multimodal learning.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-vcentered is-multiline">
      <div class="column is-12 section-image">
        <img src="static/images/fig1.png" alt="Diagram of the SCENEFORGE method">
      </div>
      <div class="column is-12">
        <div class="content has-text-centered">
          <h2>Our Approach: Structured Scene Composition</h2>
          <p>
            We introduce <strong>SCENEFORGE</strong>, a framework that synthetically creates complex multi-object 3D scenes from individual point clouds. By composing objects using explicit spatial relations (like 'next to' or 'over') and generating coherent, LLM-refined captions, we virtually expand the training data. This model-agnostic pipeline can be plugged into any 3D-text contrastive learning model to enhance its training with richer, more diverse samples, teaching it to understand not just objects, but the relationships between them.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-vcentered">
            <div class="column">
                <div class="content">
                    <h2>Consistent Gains and Enhanced Reasoning</h2>
                    <p>
                        Our method delivers substantial performance gains across multiple tasks, including zero-shot classification, few-shot segmentation, and 3D question answering. The SF-Uni3D variant even outperforms costly ensemble methods. Qualitatively, models trained with SCENEFORGE show significantly improved spatial and compositional reasoning, successfully repositioning objects to match new textual descriptions where baseline models fail, demonstrating a deeper understanding of 3D space and language.
                    </p>
                </div>
            </div>
            <div class="column section-image">
                <img src="static/images/repositioning.png" alt="Example of improved object repositioning with SCENEFORGE">
            </div>
        </div>
    </div>
</section>

<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{sbrolli2025sceneforgeenhancing3dtextalignment,
      title={SCENEFORGE: Enhancing 3D-text alignment with Structured Scene Compositions}, 
      author={Cristian Sbrolli and Matteo Matteucci},
      year={2025},
      eprint={2509.15693},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2509.15693}, 
}
</code></pre>
    </div>
</section>
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a><br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

</body>
  </html>
